{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "rC9PN65bU_5u",
        "EIZ3DMPRVLWW",
        "GDE2hrYTVLUB",
        "R3BX8dts-u0M",
        "InzzmyyeVLQw"
      ],
      "mount_file_id": "1kWB-bOxdWRiONKbFIY8C5mBDe_eLPeUu",
      "authorship_tag": "ABX9TyNelPHBvRa8W2ZoNswJePWs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/allakoala/data_science/blob/main/colab_notebooks/HW_Classification_(part_1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#HW - https://docs.google.com/document/d/1Azj1QEIid13yQNvb3mdwDyfpbgjrP7yhUG5EjKfd_u4/edit\n",
        "\n",
        "DATA - https://drive.google.com/file/d/1m53GMGvefv99ZeTOuhjb5wLkTSwfMTCf/view"
      ],
      "metadata": {
        "id": "rC9PN65bU_5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#basics\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import imblearn\n",
        "from collections import Counter\n",
        "from matplotlib import pyplot\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "id": "1EGE5sw2MWbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EDA: exploration of variables and properties of data\n",
        "\n",
        "#Conclusions:\n",
        "1. IF on_thyroxine, query_on_thyroxine, on_antithyroid_medication, sick, pregnant, thyroid_surgery, I131_treatment, query_hypothyroid, query_hyperthyroid, lithium, goitre, tumor, hypopituitary, psych, TSH_measured, T3_measured, TT4_measured, T4U_measured, FTI_measured = false,\n",
        "THEN (FTI,T4U,TSH,T3,TT4) = 0\n",
        "\n",
        "2. Missing values are imputed:\n",
        "- sex -  mode\n",
        "- age -  median\n",
        "\n",
        "3. The following features were converted to num float values:\n",
        "- age\n",
        "- TSH\n",
        "- T3\n",
        "- TT4\n",
        "- T4U\n",
        "- FTI\n",
        "\n",
        "3. Outliers except 0 values were substituted with their lower and upper quantile values respectively—é\n",
        "\n",
        "7. Target variable:\"Class\" - is imbalanced\n",
        " - negative                   3420\n",
        " - compensated_hypothyroid     194\n",
        " - primary_hypothyroid          95\n",
        " - secondary_hypothyroid         2 - SHOULD BE REMOVED!"
      ],
      "metadata": {
        "id": "EIZ3DMPRVLWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "c4uBqlBnWIn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#path of the file to read\n",
        "url = \"/content/drive/MyDrive/Colab Notebooks/dataset_57_hypothyroid.csv\"\n",
        "\n",
        "#read the file into a variable\n",
        "data = pd.read_csv(url, sep=',')\n",
        "\n",
        "#examine the data for Univariate analysis: consider features separately, their distribution, descriptive statistics, anomalies, omissions, etc\n",
        "data.head(20)"
      ],
      "metadata": {
        "id": "4H1NrVZgMmrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#find duplicate rows\n",
        "duplicate_rows = data.duplicated(subset=data.columns, keep=\"first\")\n",
        "duplicate_rows.sum()"
      ],
      "metadata": {
        "id": "Uhc3oJs9NqGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove duplicate rows\n",
        "#data = data[~duplicate_rows]\n",
        "data = data.drop_duplicates()"
      ],
      "metadata": {
        "id": "huTIHqNxN7Kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#identify the data type\n",
        "data.info()"
      ],
      "metadata": {
        "id": "jv1cU2i4N_Mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for each dataset column print unique values\n",
        "for col in data.columns:\n",
        "    n_unique_values = data[col].nunique()\n",
        "    unique_values = data[col].unique()\n",
        "    print(f\"{col}: {n_unique_values}: {unique_values}\")"
      ],
      "metadata": {
        "id": "hgOCwC5JOIBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# look at the \"?\" value count\n",
        "data.replace('?', np.nan, inplace=True)\n",
        "data.isna().sum()"
      ],
      "metadata": {
        "id": "dCdFA3IlOlNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#missing data for each variable and way to handle it\n",
        "\n",
        "total = data.isnull().sum().sort_values(ascending=False)\n",
        "percent = (data.isnull().sum()/data.isnull().count()).sort_values(ascending=False)\n",
        "total_2 = data.isna().sum().sort_values(ascending=False)\n",
        "percent_2 = (data.isna().sum()/data.isna().count()).sort_values(ascending=False)\n",
        "missing_data = pd.concat([total, percent, total_2, percent_2], axis=1, keys=['Tota_null', 'Percent_null', 'Total_na', 'Percent_na'])\n",
        "missing_data"
      ],
      "metadata": {
        "id": "tt_ks68jQhhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if TBG_measured, TSH_measured, T3_measured, TT4_measured, T4U_measured, FTI_measured = false, then TBG,FTI,T4U,TSH,T3,TT4 = 0\n",
        "# replace NaN values with 0 for columns based on their respective measured columns\n",
        "cols_to_replace = ['TBG', 'FTI', 'T4U', 'TSH', 'T3', 'TT4']\n",
        "measured_cols = ['TBG_measured', 'FTI_measured', 'T4U_measured', 'TSH_measured', 'T3_measured', 'TT4_measured']\n",
        "for col, measured_col in zip(cols_to_replace, measured_cols):\n",
        "    data[col] = data[col].where(data[measured_col] == 't', 0)\n",
        "\n",
        "data.head(10)"
      ],
      "metadata": {
        "id": "XZ5zHRwBpX92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#missing data for each variable and way to handle it\n",
        "\n",
        "total = data.isnull().sum().sort_values(ascending=False)\n",
        "percent = (data.isnull().sum()/data.isnull().count()).sort_values(ascending=False)\n",
        "total_2 = data.isna().sum().sort_values(ascending=False)\n",
        "percent_2 = (data.isna().sum()/data.isna().count()).sort_values(ascending=False)\n",
        "missing_data = pd.concat([total, percent, total_2, percent_2], axis=1, keys=['Tota_null', 'Percent_null', 'Total_na', 'Percent_na'])\n",
        "missing_data"
      ],
      "metadata": {
        "id": "p0Lotp_-sXMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert age, TSH, T3, TT4, T4U, FTI float data type\n",
        "data[['age', 'TSH', 'T3', 'TT4', 'T4U', 'FTI']] = data[['age', 'TSH', 'T3', 'TT4', 'T4U', 'FTI']].astype(float)"
      ],
      "metadata": {
        "id": "xTy82WCPWJA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#devide features into num and categirical\n",
        "\n",
        "#empty lists for numerical and categorical features\n",
        "numerical_cols = []\n",
        "categorical_cols = []\n",
        "\n",
        "#loop over each column and determine its data type\n",
        "for col in data.columns:\n",
        "    if data[col].dtype == 'object':\n",
        "        categorical_cols.append(col)\n",
        "    else:\n",
        "        numerical_cols.append(col)\n",
        "\n",
        "print(\"All columns:\", data.columns)\n",
        "print(\"Numerical features:\", numerical_cols)\n",
        "print(\"Categorical features:\", categorical_cols)"
      ],
      "metadata": {
        "id": "j5J_X9QMpLLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace missing values in sex column with mode\n",
        "data['sex'].fillna(data['sex'].mode()[0], inplace=True)\n",
        "\n",
        "# replace missing values in age column with median\n",
        "data['age'].fillna(data['age'].median(), inplace=True)\n",
        "\n",
        "# print the first 10 rows of the updated dataset\n",
        "print(data)"
      ],
      "metadata": {
        "id": "_Nu1XHjTt48a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#missing data for each variable and way to handle it\n",
        "\n",
        "total = data.isnull().sum().sort_values(ascending=False)\n",
        "percent = (data.isnull().sum()/data.isnull().count()).sort_values(ascending=False)\n",
        "total_2 = data.isna().sum().sort_values(ascending=False)\n",
        "percent_2 = (data.isna().sum()/data.isna().count()).sort_values(ascending=False)\n",
        "missing_data = pd.concat([total, percent, total_2, percent_2], axis=1, keys=['Tota_null', 'Percent_null', 'Total_na', 'Percent_na'])\n",
        "missing_data"
      ],
      "metadata": {
        "id": "oDQh7Fo5ucPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.hist(figsize = (20,20));"
      ],
      "metadata": {
        "id": "3MG4NjWwcxi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#continuous variables distribution visualization using a histogram\n",
        "\n",
        "#summary statistics of the numerical features\n",
        "print(data[numerical_cols].describe())\n",
        "\n",
        "#the histogram is colored by the target variable 'y' (which is binary) to see the differences in the distribution between the two target classes.\n",
        "for col in numerical_cols:\n",
        "    sns.histplot(data=data, x=col, kde=True)\n",
        "    plt.show()\n",
        "\n",
        "#lists of columns with specified characteristics\n",
        "stats = data[numerical_cols].describe()\n",
        "print(f\"\\nColumns with mean < median:\\n{stats.columns[stats.loc['mean'] < stats.loc['50%']]}\")\n",
        "print(f\"\\nColumns with mean > median:\\n{stats.columns[stats.loc['mean'] > stats.loc['50%']]}\")\n",
        "print(f\"\\nColumns with big difference between (75th %tile and max) or/and (25th %tile and min values):\\n{stats.columns[((stats.loc['75%'] - stats.loc['max']).abs() > 100) | ((stats.loc['25%'] - stats.loc['min']).abs() > 100)]}\")\n",
        "print(f\"\\nColumns with high standard deviation:\\n{stats.columns[stats.loc['std'] > 100]}\")\n",
        "print(f\"\\nColumns with low standard deviation:\\n{stats.columns[stats.loc['std'] < 0.1]}\")"
      ],
      "metadata": {
        "id": "gOstDGMQp7e4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# create empty lists for positive and negative slopes\n",
        "positive_slope_pairs = []\n",
        "negative_slope_pairs = []\n",
        "\n",
        "for i in range(len(numerical_cols)):\n",
        "    for j in range(i+1, len(numerical_cols)):\n",
        "        # calculate the slope of the regression line\n",
        "        slope = data[numerical_cols[j]].corr(data[numerical_cols[i]])\n",
        "\n",
        "        # create scatter plot with color-coded points\n",
        "        sns.scatterplot(x=numerical_cols[i], y=numerical_cols[j], data=data)\n",
        "\n",
        "        # add regression line\n",
        "        sns.regplot(x=numerical_cols[i], y=numerical_cols[j], data=data, scatter=False, color=\"black\")\n",
        "\n",
        "        # set plot title and axis labels\n",
        "        plt.title(f\"{numerical_cols[i]} vs {numerical_cols[j]}\")\n",
        "        plt.xlabel(numerical_cols[i])\n",
        "        plt.ylabel(numerical_cols[j])\n",
        "\n",
        "        # append feature pair to the appropriate list based on the sign of the slope\n",
        "        if slope > 0:\n",
        "            positive_slope_pairs.append(f\"{numerical_cols[i]} vs {numerical_cols[j]}\")\n",
        "        elif slope < 0:\n",
        "            negative_slope_pairs.append(f\"{numerical_cols[i]} vs {numerical_cols[j]}\")\n",
        "\n",
        "        # display plot\n",
        "        plt.show()\n",
        "\n",
        "        # clear current figure to free up memory\n",
        "        plt.clf()\n",
        "\n",
        "# print out the lists of feature pairs\n",
        "print(\"Feature pairs with positive slopes:\")\n",
        "for feature_pair in positive_slope_pairs:\n",
        "    print(feature_pair)\n",
        "\n",
        "print(\"\\nFeature pairs with negative slopes:\")\n",
        "for feature_pair in negative_slope_pairs:\n",
        "    print(feature_pair)"
      ],
      "metadata": {
        "id": "ol0E8ynDqHVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#heatmap style\n",
        "sns.set(style='darkgrid')\n",
        "corrmat = data.corr()\n",
        "f, ax = plt.subplots(figsize=(12, 9))\n",
        "sns.heatmap(corrmat, annot=True, fmt=\".2f\", cmap='coolwarm', vmax=.8, square=True)\n",
        "plt.show()\n",
        "\n",
        "# print highly positively correlated pairs\n",
        "pos_corr_pairs = []\n",
        "for i in range(len(corrmat.columns)):\n",
        "    for j in range(i+1, len(corrmat.columns)):\n",
        "        if abs(corrmat.iloc[i, j]) >= 0.5:\n",
        "            pos_corr_pairs.append((corrmat.columns[i], corrmat.columns[j]))\n",
        "\n",
        "print(\"Highly positively correlated pairs:\")\n",
        "for pair in pos_corr_pairs:\n",
        "    print(pair)\n",
        "\n",
        "# print highly negatively correlated pairs\n",
        "neg_corr_pairs = []\n",
        "for i in range(len(corrmat.columns)):\n",
        "    for j in range(i+1, len(corrmat.columns)):\n",
        "        if abs(corrmat.iloc[i, j]) <=  -0.5:\n",
        "            neg_corr_pairs.append((corrmat.columns[i], corrmat.columns[j]))\n",
        "\n",
        "print(\"Highly negatively correlated pairs:\")\n",
        "for pair in neg_corr_pairs:\n",
        "    print(pair)"
      ],
      "metadata": {
        "id": "JsNV36O2qUbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#frequency table of the categorical features\n",
        "\n",
        "for col in categorical_cols:\n",
        "  print(f\"\\n{col}:\")\n",
        "  print(data[col].value_counts())\n",
        "\n",
        "#distribution of the categorical features visualisation using a bar plot\n",
        "plt.style.use('seaborn-darkgrid')\n",
        "plt.rcParams.update({'font.size': 12})\n",
        "\n",
        "for col in categorical_cols:\n",
        "        plt.figure(figsize=(20,7))\n",
        "        sns.countplot(data=data, x=col)\n",
        "        plt.xticks(rotation=90)\n",
        "        plt.xlabel(col, fontsize=14)\n",
        "        plt.ylabel('Count', fontsize=14)\n",
        "        plt.title(f'Distribution of {col}', fontsize=16)\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "ojSKLTVCqqYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#outliers detection - Interquartile Range (IQR) method (values outside the normal range)\n",
        "for col in numerical_cols:\n",
        "    vals = data[col].values\n",
        "    q1, q3 = np.percentile(vals, [25, 75])\n",
        "    iqr = q3 - q1\n",
        "    lower = q1 - 1.5 * iqr\n",
        "    upper = q3 + 1.5 * iqr\n",
        "    outliers = vals[(vals < lower) | (vals > upper)]\n",
        "    unique_vals = data[col][data[col].isin(outliers)].value_counts()\n",
        "    print(f\"{col} has {len(outliers)} outliers with the following unique value counts:\\n{unique_vals}\\n\")"
      ],
      "metadata": {
        "id": "y5WIzQ8h0DvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in numerical_cols:\n",
        "    zero_vals = data.loc[data[col].isin([0, 0.0, 0.00]), col]\n",
        "    print(f\"{col} has {len(zero_vals)} rows with a value of 0, 0.0, or 0.00:\\n{zero_vals}\\n\")"
      ],
      "metadata": {
        "id": "J2FaXsO1s4Sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for outlier in outliers:\n",
        "    if outlier not in [0, 0.0, 0.00]:\n",
        "        if outlier < lower:\n",
        "            data[col][data[col] == outlier] = lower\n",
        "        else:\n",
        "            data[col][data[col] == outlier] = upper"
      ],
      "metadata": {
        "id": "tSvvWA46r669"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in numerical_cols:\n",
        "    zero_vals = data.loc[data[col].isin([0, 0.0, 0.00]), col]\n",
        "    print(f\"{col} has {len(zero_vals)} rows with a value of 0, 0.0, or 0.00:\\n{zero_vals}\\n\")"
      ],
      "metadata": {
        "id": "5Hw7htgvsiR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorical encoding for y\n",
        "labelencoder = LabelEncoder()\n",
        "data['y'] = labelencoder.fit_transform(data['Class'])\n",
        "print(data['y'].value_counts())\n",
        "print(data['y'])"
      ],
      "metadata": {
        "id": "v-8Tspsx_jvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out entries where y = 3\n",
        "data = data[data['y'] != 3]\n",
        "y=data['y']\n",
        "print(y.value_counts())\n",
        "print(y)"
      ],
      "metadata": {
        "id": "GqpwKWC8iZdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.close();\n",
        "sns.set_style('whitegrid');\n",
        "sns.pairplot(data, hue='y', height=3);\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0BsfZ-0UMIC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data preprocessing:\n",
        "1. sex and referral_source are  encoded with dummy data\n",
        "2. on_thyroxine,  query_on_thyroxine, on_antithyroid_medication, sick, pregnant, thyroid_surgery, I131_treatment, query_hypothyroid, query_hyperthyroid, lithium, goitre, tumor, hypopituitary psych, TSH_measured, T3_measured, TT4_measured, T4U_measured, FTI_measured encode as binary data\n",
        "4. Lable encoding for y = Class\n",
        "5. Dropping unimportant features - 'sex', 'referral_source', 'Class', 'TBG','TBG_measured'\n",
        "6. Data normalization for continues features\n"
      ],
      "metadata": {
        "id": "GDE2hrYTVLUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dummy variables for the 'sex' column\n",
        "sex_dummy = pd.get_dummies(data['sex'], prefix='sex')\n",
        "sex_dummy"
      ],
      "metadata": {
        "id": "UGMMhLmfWJSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode binary columns with 1s and 0s\n",
        "binary_cols = ['on_thyroxine', 'query_on_thyroxine', 'on_antithyroid_medication',\n",
        "               'sick', 'pregnant', 'thyroid_surgery', 'I131_treatment',\n",
        "               'query_hypothyroid', 'query_hyperthyroid', 'lithium', 'goitre',\n",
        "               'tumor', 'hypopituitary', 'TSH_measured', 'T3_measured',\n",
        "               'TT4_measured', 'T4U_measured', 'FTI_measured', 'psych']\n",
        "data[binary_cols] = data[binary_cols].apply(lambda x: x.map({'t': 1, 'f': 0}))\n",
        "data"
      ],
      "metadata": {
        "id": "bFlmzOflz_ES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dummy variables for the 'referral_source' column\n",
        "referral_dummy = pd.get_dummies(data['referral_source'], prefix='referral')\n",
        "referral_dummy"
      ],
      "metadata": {
        "id": "VWbGi_d30V09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the encoded columns with the original data\n",
        "data_encoded = data.drop(['sex', 'referral_source', 'Class', 'TBG', 'TBG_measured'], axis=1) #'y'\n",
        "data_encoded = pd.merge(data_encoded, sex_dummy, left_index=True, right_index=True)\n",
        "data_encoded = pd.merge(data_encoded, referral_dummy, left_index=True, right_index=True)\n",
        "data_encoded = pd.DataFrame(data=data_encoded, columns=data_encoded.columns)\n",
        "\n",
        "data_encoded"
      ],
      "metadata": {
        "id": "qnbfLV570j_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#missing data for each variable\n",
        "\n",
        "total = data_encoded.isnull().sum().sort_values(ascending=False)\n",
        "percent = (data_encoded.isnull().sum()/data_encoded.isnull().count()).sort_values(ascending=False)\n",
        "\n",
        "missing_data = pd.concat([total, percent], axis=1, keys=['Tota_null', 'Percent_null'])\n",
        "missing_data"
      ],
      "metadata": {
        "id": "2H8o3dIeVqSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# separate binary features from continuous numerical features\n",
        "binary_features = ['y'] + [col for col in data_encoded.columns if data_encoded[col].nunique() == 2]\n",
        "numerical_features = [col for col in data_encoded.columns if col not in binary_features]\n",
        "\n",
        "# print the binary and numerical features\n",
        "print(\"Binary Features: \", binary_features)\n",
        "print(\"Numerical Features: \", numerical_features)"
      ],
      "metadata": {
        "id": "z1FW2CSu78Nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data normalization - Standardization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler_s = StandardScaler().fit(data_encoded[numerical_features])\n",
        "rescaled_d = scaler_s.transform(data_encoded[numerical_features])\n",
        "#np.set_printoptions(precision=3)\n",
        "\n",
        "# create a new dataframe with the rescaled numerical features\n",
        "rescaled_df = pd.DataFrame(data=rescaled_d, columns=numerical_features)\n",
        "rescaled_df"
      ],
      "metadata": {
        "id": "xo5Kq_5V2YKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#missing data for each variable\n",
        "\n",
        "total = rescaled_df.isnull().sum().sort_values(ascending=False)\n",
        "percent = (rescaled_df.isnull().sum()/rescaled_df.isnull().count()).sort_values(ascending=False)\n",
        "\n",
        "missing_data = pd.concat([total, percent], axis=1, keys=['Tota_null', 'Percent_null'])\n",
        "missing_data"
      ],
      "metadata": {
        "id": "OeXeIb0ukgB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the binary and numerical features\n",
        "data_rescaled = data_encoded[binary_features].merge(rescaled_df, how='inner', left_index=True, right_index=True)\n",
        "#data_rescaled = data_encoded[binary_features].merge(rescaled_df, how='inner', on='index')\n",
        "#data_rescaled = pd.merge(data_encoded[binary_features], rescaled_df, left_index=True, right_index=True)\n",
        "print(data_rescaled)"
      ],
      "metadata": {
        "id": "gf6PMDDEkRo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the binary and numerical features and convert to numeric - nan values - ???\n",
        "#data_rescaled = data_encoded[binary_features].join(rescaled_df)\n",
        "#data_rescaled"
      ],
      "metadata": {
        "id": "UG3A1DNabQMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#missing data\n",
        "\n",
        "total = data_rescaled.isnull().sum().sort_values(ascending=False)\n",
        "percent = (data_rescaled.isnull().sum()/data_rescaled.isnull().count()).sort_values(ascending=False)\n",
        "\n",
        "missing_data = pd.concat([total, percent], axis=1, keys=['Tota_null', 'Percent_null'])\n",
        "missing_data"
      ],
      "metadata": {
        "id": "oK-zL7eNkz0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data balancing:\n",
        "1. SMOTE: Class=1, n=3367 (33.333%)\n",
        "Class=0, n=3367 (33.333%)\n",
        "Class=2, n=3367 (33.333%)\n",
        "2. RandomForestClassifier - Mean Accuracy: 0.922 (0.001)\n",
        "3. Resample technique: 1:    2533\n",
        "0:    2533\n",
        "2:    2533"
      ],
      "metadata": {
        "id": "R3BX8dts-u0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_rescaled['y'].value_counts())\n",
        "y = data_rescaled['y'].values\n",
        "# y = y.values\n",
        "print('y:', y.shape)\n",
        "X = data_rescaled.drop('y', axis=1).values\n",
        "print('X:', X.shape)"
      ],
      "metadata": {
        "id": "Q0y3p5T5Y17e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "oversample = SMOTE(k_neighbors=10) #https://machinelearningmastery.com/multi-class-imbalanced-classification/\n",
        "X_resampled, y_resampled = oversample.fit_resample(X, y) #ValueError: Expected n_neighbors <= n_samples,  but n_samples = 2, n_neighbors = 3\n",
        "\n",
        "#summarize distribution\n",
        "counter = Counter(y_resampled)\n",
        "for k, v in counter.items():\n",
        "   per = v / len(y_resampled) * 100\n",
        "   print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
        "\n",
        "#plot the distribution\n",
        "pyplot.bar(counter.keys(), counter.values())\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "hhRQ3bDQ3bym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomForestClassifier: https://machinelearningmastery.com/multi-class-imbalanced-classification/\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from pandas import read_csv\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# evaluate a model\n",
        "def evaluate_model(X, y, model):\n",
        "  # define evaluation procedure\n",
        "  cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=3, random_state=1)\n",
        "  # evaluate model\n",
        "  scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  return scores\n",
        "\n",
        "# define the model\n",
        "weights = {0:10.0, 1:1.0, 2:30.0, 3:100.0}\n",
        "model = RandomForestClassifier(n_estimators=1000, class_weight=weights)\n",
        "# evaluate the model\n",
        "scores = evaluate_model(X, y, model)\n",
        "# summarize performance\n",
        "print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
      ],
      "metadata": {
        "id": "AhSHD3LOU2m8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample #https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18 Undersample majority class - ?\n",
        "\n",
        "y = data_rescaled['y']\n",
        "X = data_rescaled.drop('y', axis=1)\n",
        "\n",
        "# setting up testing and training sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)\n",
        "\n",
        "# concatenate our training data back together\n",
        "X = pd.concat([X_train, y_train], axis=1)\n",
        "\n",
        "# separate minority and majority classes\n",
        "neg = X[X.y==0]\n",
        "pos_1 = X[X.y==1]\n",
        "pos_2 = X[X.y==2]\n",
        "\n",
        "# upsample minority\n",
        "neg_upsampled = resample(neg,\n",
        "                          replace=True, # sample with replacement\n",
        "                          n_samples=len(pos_1), # match number in majority class\n",
        "                          random_state=27) # reproducible results\n",
        "\n",
        "pos_2_upsampled = resample(pos_2,\n",
        "                          replace=True, # sample with replacement\n",
        "                          n_samples=len(pos_1), # match number in majority class\n",
        "                          random_state=27) # reproducible results\n",
        "\n",
        "# combine majority and upsampled minority\n",
        "upsampled = pd.concat([pos_1, neg_upsampled, pos_2_upsampled,])\n",
        "\n",
        "# check new class counts\n",
        "upsampled.y.value_counts()\n",
        "\n",
        "#X_t, y_t\n",
        "y_train = upsampled.y\n",
        "X_train = upsampled.drop('y', axis=1)"
      ],
      "metadata": {
        "id": "T1T_FLqc824q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Metrics and cross-validation have been chosen based on target distribution as well as reasoning behind:\n",
        "\n",
        "1. Considering the algorithm https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/: predicting class labels, False Positives More Important: Use F0.5-Measure\n",
        "\n",
        "3. Precision and recall to focus on small positive class ‚Äî When the positive class is smaller and the ability to detect correctly positive samples is our main focus (correct detection of negatives examples is less important to the problem) we should use precision and recall.\n",
        "\n",
        "4.  ROC  - when the positives are the majority or switch the labels and use precision and recall ‚Äî When the positive class is larger we should probably use the ROC metrics because the precision and recall would reflect mostly the ability of prediction of the positive class and not the negative class which will naturally be harder to detect due to the smaller number of samples. If the negative class (the minority in this case) is more important, we can switch the labels and use precision and recall (labels=[pos_label] - ?). https://towardsdatascience.com/what-metrics-should-we-use-on-imbalanced-data-set-precision-recall-roc-e2e79252aeba\n"
      ],
      "metadata": {
        "id": "InzzmyyeVLQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics and cross-validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "import warnings\n",
        "\n",
        "# suppress convergence warnings\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "# define KNN and Logistic Regression models\n",
        "knn = KNeighborsClassifier()\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# K-Fold Cross-Validation\n",
        "knn_scores = cross_val_score(knn, X_train, y_train, cv=5)\n",
        "lr_scores = cross_val_score(lr, X_train, y_train, cv=5)\n",
        "\n",
        "# print results\n",
        "print(\"KNN scores: {:.2f} +/- {:.2f}\".format(knn_scores.mean(), knn_scores.std()))\n",
        "print(\"Logistic Regression scores: {:.2f} +/- {:.2f}\".format(lr_scores.mean(), lr_scores.std()))"
      ],
      "metadata": {
        "id": "q35vr-6rgKrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature importance and hyperparameters tuning: https://scikit-learn.org/stable/modules/classes.html#hyper-parameter-optimizers\n",
        "\n",
        "1. GridSearchCV with knn: Best score: 0.9415708048924154 Best params: {'n_neighbors': 3}\n",
        "2. HalvingGridSearchCV with knn: Best score: 0.9415323339587015 Best params: {'n_neighbors': 3}\n",
        "3. RandomizedSearchCV with knn: Best score: 0.9415708048924154 Best params: {'n_neighbors': 3}\n",
        "4. HalvingRandomSearchCV with knn: Best score: 0.44565217391304346 Best params: {'n_neighbors': 20}\n",
        "5. GridSearchCV with logistic: Best score: 0.49533115623159285 Best params: {'C': 0.1, 'penalty': 'l2'}\n",
        "6. HalvingRandomSearchCV with logistic: best score = 0.4640070921985816, best params = {'penalty': 'l2', 'C': 10}\n",
        "7. RandomizedSearchCV with logistic: best score = 0.49533115623159285, best params = {'penalty': 'l2', 'C': 0.1}\n",
        "8. HalvingRandomSearchCV with logistic: best score = 0.4640070921985816, best params = {'penalty': 'l2', 'C': 10}\n",
        "9. GridSearchCV with lgbm: best score = 0.993946069089775, best params = {'learning_rate': 0.1, 'n_estimators': 300}\n",
        "\n",
        "10. HalvingGridSearchCV with lgbm: best score = 0.9935356200527705, best params = {'learning_rate': 0.1, 'n_estimators': 300}\n",
        "\n",
        "\n",
        "\n",
        "11. RandomizedSearchCV with lgbm: best score = 0.993946069089775, best params = {'n_estimators': 300, 'learning_rate': 0.1}\n",
        "\n",
        "\n",
        "12. HalvingRandomSearchCV with lgbm: best score = 0.7494517543859649, best params = {'n_estimators': 300, 'learning_rate': 0.1}\n",
        "\n",
        "13.\n",
        "\tFeature importance for lgbm\n",
        "\n",
        "| Feature                    | Importance |\n",
        "| --------------------------| ----------|\n",
        "| age                        | 5100      |\n",
        "| TSH                        | 4435      |\n",
        "| TT4                        | 3735      |\n",
        "| T4U                        | 3658      |\n",
        "| FTI                        | 3250      |\n",
        "| T3                         | 2564      |\n",
        "| sex_F                      | 461       |\n",
        "| referral_other            | 380       |\n",
        "| T3_measured                | 343       |\n",
        "| query_hypothyroid          | 324       |\n",
        "| referral_SVI               | 280       |\n",
        "| query_hyperthyroid         | 251       |\n",
        "| T4U_measured               | 223       |\n",
        "| thyroid_surgery            | 217       |\n",
        "| psych                      | 200       |\n",
        "| referral_SVHC              | 176       |\n",
        "| on_thyroxine               | 175       |\n",
        "| referral_STMW              | 171       |\n",
        "| tumor                      | 167       |\n",
        "| TT4_measured               | 163       |\n",
        "| sick                       | 143       |\n",
        "| I131_treatment             | 114       |\n",
        "| TSH_measured               | 101       |\n",
        "| query_on_thyroxine         | 88        |\n",
        "| sex_M                      | 76        |\n",
        "| goitre                     | 50        |\n",
        "| on_antithyroid_medication  | 49        |\n",
        "| referral_SVHD              | 40        |\n",
        "| FTI_measured               | 27        |\n",
        "| pregnant                   | 25        |\n",
        "| lithium                    | 14        |\n",
        "| hypopituitary              | 0         |\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aYJvseAKVLN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import (\n",
        "    GridSearchCV,\n",
        "    HalvingGridSearchCV,\n",
        "    RandomizedSearchCV,\n",
        "    HalvingRandomSearchCV,\n",
        ")\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    \"knn\": KNeighborsClassifier(),\n",
        "    \"logistic\": LogisticRegression(),\n",
        "    \"lgbm\": LGBMClassifier()\n",
        "}\n",
        "\n",
        "# Define hyperparameters to tune for each model\n",
        "hyperparameters = {\n",
        "    \"knn\": {\"n_neighbors\": [3, 5, 7, 10, 20, 50]},\n",
        "    \"logistic\": {\"penalty\": [\"l1\", \"l2\"], \"C\": [0.1, 1, 10, 100, 1000]},\n",
        "    \"lgbm\": {\"learning_rate\": [0.01, 0.1, 1, 10, 100, 1000], \"n_estimators\": [50, 100, 200, 300]}\n",
        "}\n",
        "\n",
        "# Define optimizers to use for hyperparameter tuning\n",
        "optimizers = [\n",
        "    GridSearchCV,\n",
        "    HalvingGridSearchCV,\n",
        "    RandomizedSearchCV,\n",
        "    HalvingRandomSearchCV\n",
        "]\n",
        "\n",
        "# Loop over each model and optimizer, and perform hyperparameter tuning\n",
        "for model_name, model in models.items():\n",
        "    for optimizer in optimizers:\n",
        "        # Create parameter grid for hyperparameter tuning\n",
        "        param_grid = hyperparameters[model_name]\n",
        "\n",
        "        # Initialize optimizer and fit to data\n",
        "        try:\n",
        "            if optimizer in [HalvingGridSearchCV, HalvingRandomSearchCV]:\n",
        "                clf = optimizer(model, param_grid, scoring=\"accuracy\", n_jobs=-1, factor=2, cv=5)\n",
        "            else:\n",
        "                clf = optimizer(model, param_grid, scoring=\"accuracy\", n_jobs=-1, cv=5)\n",
        "\n",
        "            clf.fit(X_train, y_train)\n",
        "\n",
        "            # Print results\n",
        "            print(f\"{optimizer.__name__} with {model_name}: best score = {clf.best_score_}, best params = {clf.best_params_}\")\n",
        "\n",
        "            # Fit model with best hyperparameters and print feature importance (if available)\n",
        "            best_model = clf.best_estimator_\n",
        "            best_model.fit(X_train, y_train)\n",
        "            if hasattr(best_model, 'feature_importances_'):\n",
        "                feature_importance = pd.DataFrame(list(zip(X.columns, best_model.feature_importances_)), columns=[\"Feature\", \"Importance\"])\n",
        "                feature_importance = feature_importance.sort_values(\"Importance\", ascending=False)\n",
        "                print(f\"Feature importance for {model_name}:\")\n",
        "                print(feature_importance)\n",
        "        except (ValueError, RuntimeError) as e:\n",
        "            warnings.warn(str(e))"
      ],
      "metadata": {
        "id": "RY8_v2kE-dU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Models evaluation:\n",
        "\n",
        "1. K-nearest neighbours https://towardsdatascience.com/multiclass-classification-using-k-nearest-neighbours-ca5281a9ef76\n",
        "2. Logistic Regression w\\wo regularization https://machinelearningmastery.com/multinomial-logistic-regression-with-python/\n",
        "3. LGBM classifier\n",
        "\n",
        "#Conclusions:\n",
        "1. The LGBM classifier performed the best in predicting the target variable, with a high accuracy and good precision, recall, and F1 score for most classes.\n",
        "2. The K-nearest neighbors model had an accuracy of 0.749, indicating that it correctly predicted the target variable around 75% of the time.\n",
        "3. The confusion matrix for the K-nearest neighbors model showed that the model performed poorly in predicting classes 0 and 2, with a low precision, recall, and F1 score. The model performed the best in predicting class 1, with a high precision, recall, and F1 score.\n",
        "4. The logistic regression without regularization model had a very low accuracy of 0.33, indicating poor performance in predicting the target variable.\n",
        "5. The confusion matrix for the logistic regression without regularization model showed that the model performed very poorly in predicting classes 0 and 2, with a low precision, recall, and F1 score. The model performed better in predicting class 1, with a high precision, recall, and F1 score.\n",
        "6. The logistic regression with L2 regularization model had a slightly better accuracy of 0.32 than the previous model, but it still performed poorly in predicting the target variable.\n",
        "7. The confusion matrix for the logistic regression with L2 regularization model showed that the model performed very poorly in predicting classes 0 and 2, with a low precision, recall, and F1 score. The model performed better in predicting class 1, with a high precision, recall, and F1 score.\n",
        "8. The LGBM classifier had an accuracy of 0.924, indicating good performance in predicting the target variable.\n",
        "9. The confusion matrix for the LGBM classifier showed that the model performed well in predicting classes 0, 1, and 2, with a high precision, recall, and F1 score. However, the model performed poorly in predicting class 3, which had no samples in the dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "8k1klEehVK1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U scikit-learn"
      ],
      "metadata": {
        "id": "KyNSExm3_uuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (classification_report, confusion_matrix, accuracy_score,\n",
        "                             precision_score, recall_score, f1_score, fbeta_score,\n",
        "                             roc_curve, roc_auc_score, average_precision_score,\n",
        "                             log_loss, brier_score_loss)\n",
        "import warnings\n",
        "from sklearn.exceptions import UndefinedMetricWarning\n",
        "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
        "\n",
        "# Fit K-nearest neighbours classifier\n",
        "knn_clf = KNeighborsClassifier(n_neighbors=3)\n",
        "knn_clf.fit(X_train, y_train)\n",
        "y_pred_knn_clf = knn_clf.predict(X_test)\n",
        "\n",
        "# Evaluate performance\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_test, y_pred_knn_clf))\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test, y_pred_knn_clf))\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred_knn_clf))\n",
        "\n",
        "try:\n",
        "  print('Sensitivity:', recall_score(y_test, y_pred_knn_clf, average='weighted'))\n",
        "except:\n",
        "  print('Sensitivity: Undefined')\n",
        "\n",
        "try:\n",
        "  print('Specificity:', recall_score(y_test, y_pred_knn_clf, average='weighted', pos_label=0))\n",
        "except:\n",
        "  print('Specificity: Undefined')\n",
        "\n",
        "print('G-Mean:', (recall_score(y_test, y_pred_knn_clf, average='weighted') * recall_score(y_test, y_pred_knn_clf, average='weighted')) ** 0.5)\n",
        "\n",
        "print('Precision:', precision_score(y_test, y_pred_knn_clf, average='weighted', labels=[0, 1, 2, 3]))\n",
        "print('Recall:', recall_score(y_test, y_pred_knn_clf, average='weighted', labels=[0, 1, 2, 3]))\n",
        "print('F1 Score:', f1_score(y_test, y_pred_knn_clf, average='weighted', labels=[0, 1, 2, 3]))\n",
        "print('F0.5 Score:', fbeta_score(y_test, y_pred_knn_clf, beta=0.5, average='weighted', labels=[0, 1, 2, 3]))\n",
        "print('F1 Score (weighted):', f1_score(y_test, y_pred_knn_clf, average='weighted', labels=[0, 1, 2, 3]))\n",
        "\n",
        "# # Compute ROC curve and AUC score - doesnt work for multiclass - ?\n",
        "# y_prob_knn_clf = knn_clf.predict_proba(X_test)[:, 1]\n",
        "# fpr, tpr, thresholds = roc_curve(y_test, y_prob_knn_clf)\n",
        "# print('ROC Curve:')\n",
        "# print('False Positive Rates:', fpr)\n",
        "# print('True Positive Rates:', tpr)\n",
        "# print('ROC AUC Score:', roc_auc_score(y_test, y_prob_knn_clf))\n",
        "\n",
        "# # Compute PR curve and AUC score\n",
        "# precision, recall, thresholds = precision_recall_curve(y_test, y_prob_knn_clf)\n",
        "# print('PR Curve:')\n",
        "# print('Precision:', precision)\n",
        "# print('Recall:', recall)\n",
        "# print('PR AUC Score:', average_precision_score(y_test, y_prob_knn_clf))\n",
        "\n",
        "# # Compute log loss and Brier score\n",
        "# print('Log Loss:', log_loss(y_test, y_prob_knn_clf))\n",
        "# print('Brier Score:', brier_score_loss(y_test, y_prob_knn_clf))\n",
        "# print('Brier Skill Score:', brier_score_loss(y_test, y_prob_knn_clf) - brier_score_loss(y_test, y_test))"
      ],
      "metadata": {
        "id": "QM9Wq_SkLaK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression model without regularization https://ml-cheatsheet.readthedocs.io/en/latest/logistic_regression.html - ?\n",
        "import warnings\n",
        "from sklearn.exceptions import UndefinedMetricWarning\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (accuracy_score, average_precision_score, brier_score_loss, classification_report, confusion_matrix, f1_score, fbeta_score, log_loss, precision_score, recall_score, roc_auc_score, roc_curve)\n",
        "\n",
        "#Ignore undefined metric warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
        "\n",
        "#Create and fit logistic regression model without regularization\n",
        "lr_clf = LogisticRegression(penalty='none')\n",
        "lr_clf.fit(X_train, y_train)\n",
        "\n",
        "#Make predictions on test data\n",
        "y_pred_lr = lr_clf.predict(X_test)\n",
        "\n",
        "#Print model performance metrics\n",
        "print('Logistic Regression without regularization model')\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_test, y_pred_lr))\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred_lr))\n",
        "\n",
        "#Calculate performance metrics\n",
        "try:\n",
        "  print('Sensitivity:', recall_score(y_test, y_pred_lr, average='weighted'))\n",
        "except UndefinedMetricWarning:\n",
        "  print('Sensitivity: Undefined')\n",
        "\n",
        "try:\n",
        "  print('Specificity:', recall_score(y_test, y_pred_lr, average='weighted', pos_label=0)) #\n",
        "except UndefinedMetricWarning:\n",
        "  print('Specificity: Undefined')\n",
        "\n",
        "print('G-Mean:', (recall_score(y_test, y_pred_lr, average='weighted') * recall_score(y_test, y_pred_lr, average='weighted')) ** 0.5)\n",
        "\n",
        "print('Precision:', precision_score(y_test, y_pred_lr, average='weighted', labels=[0, 1, 2, 3]))\n",
        "print('Recall:', recall_score(y_test, y_pred_lr, average='weighted', labels=[0, 1, 2, 3]))\n",
        "print('F-Measure:', f1_score(y_test, y_pred_lr, average='weighted', labels=[0, 1, 2, 3]))\n",
        "print('F0.5-Measure:', fbeta_score(y_test, y_pred_lr, beta=0.5, average='weighted', labels=[0, 1, 2, 3]))\n",
        "print('F1-Measure:', fbeta_score(y_test, y_pred_lr, beta=1, average='weighted'))\n",
        "\n",
        "# #Calculate and print ROC curve and AUC  - doesnt work for multiclass - ?\n",
        "# fpr, tpr, _ = roc_curve(y_test, y_pred_lr)\n",
        "# print('ROC curve:', fpr, tpr)\n",
        "# print('True Positive Rate:', tpr)\n",
        "# print('False Positive Rate:', fpr)\n",
        "# print('ROC AUC:', roc_auc_score(y_test, y_pred_lr))\n",
        "\n",
        "# #Calculate and print PR AUC and log loss\n",
        "# print('PR AUC:', average_precision_score(y_test, y_pred_lr, average='weighted'))\n",
        "# print('Log Loss:', log_loss(y_test, y_pred_lr))\n",
        "\n",
        "# #Calculate and print Brier score loss and skill score\n",
        "# print('Brier Score Loss:', brier_score_loss(y_test, y_pred_lr))\n",
        "# print('Brier Skill Score:', brier_score_loss(y_test, y_pred_lr) - brier_score_loss(y_test, y_test.mean()))"
      ],
      "metadata": {
        "id": "YVHuQ_MKVDBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression model with L2 regularization\n",
        "lr_l2 = LogisticRegression(C=100, penalty='l2')\n",
        "lr_l2.fit(X_train, y_train)\n",
        "y_pred_lr_l2 = lr_l2.predict(X_test)\n",
        "\n",
        "# Print confusion matrix and classification report\n",
        "print('Logistic Regression with L2 regularization')\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_test, y_pred_lr_l2))\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test, y_pred_lr_l2))\n",
        "\n",
        "# Calculate and print evaluation metrics\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred_lr_l2))\n",
        "\n",
        "print('G-Mean:', (recall_score(y_test, y_pred_lr_l2, average='weighted') * recall_score(y_test, y_pred_lr_l2, average='weighted')) ** 0.5)\n",
        "\n",
        "print('Precision:', precision_score(y_test, y_pred_lr_l2, average='weighted', labels=[0, 1, 2, 3]))\n",
        "print('Recall:', recall_score(y_test, y_pred_lr_l2, average='weighted', labels=[0, 1, 2, 3]))\n",
        "print('F-Measure:', f1_score(y_test, y_pred_lr_l2, average='weighted', labels=[0, 1, 2, 3]))\n",
        "print('F0.5-Measure:', fbeta_score(y_test, y_pred_lr_l2, beta=0.5, average='weighted', labels=[0, 1, 2, 3]))\n",
        "print('F1-Measure:', fbeta_score(y_test, y_pred_lr_l2, beta=1, average='weighted', labels=[0, 1, 2, 3]))\n",
        "\n",
        "#Set zero_division parameter to avoid the \"UndefinedMetricWarning\"\n",
        "print('Sensitivity:', recall_score(y_test, y_pred_lr_l2, zero_division=1, average='weighted'))\n",
        "print('Specificity:', recall_score(y_test, y_pred_lr_l2, pos_label=0, zero_division=1, average='weighted'))\n",
        "\n",
        "# fpr, tpr, _ = roc_curve(y_test, y_pred_lr_l2) #doesnt work\n",
        "# print('ROC curve:', fpr, tpr)\n",
        "# print('True Positive Rate:', tpr)\n",
        "# print('False Positive Rate:', fpr)\n",
        "# print('ROC AUC:', roc_auc_score(y_test, y_pred_lr_l2))\n",
        "# print('PR AUC:', average_precision_score(y_test, y_pred_lr_l2, average='weighted'))\n",
        "# print('Log Loss:', log_loss(y_test, y_pred_lr_l2))\n",
        "# print('Brier Score Loss:', brier_score_loss(y_test, y_pred_lr_l2))\n",
        "# print('Brier Skill Score:', brier_score_loss(y_test, y_pred_lr_l2) - brier_score_loss(y_test, y_test.mean()))"
      ],
      "metadata": {
        "id": "kOfhkcARlOUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import (classification_report, confusion_matrix, accuracy_score,\n",
        "                             precision_score, recall_score, f1_score, fbeta_score)\n",
        "\n",
        "# Fit LGBM classifier\n",
        "lgbm_clf = LGBMClassifier(learning_rate=0.1, n_estimators=300)\n",
        "lgbm_clf.fit(X_train, y_train)\n",
        "y_pred_lgbm_clf = lgbm_clf.predict(X_test)\n",
        "\n",
        "# Evaluate performance\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_test, y_pred_lgbm_clf))\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test, y_pred_lgbm_clf))\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred_lgbm_clf))\n",
        "\n",
        "try:\n",
        "  print('Sensitivity:', recall_score(y_test, y_pred_lgbm_clf, average='weighted'))\n",
        "except:\n",
        "  print('Sensitivity: Undefined')\n",
        "\n",
        "try:\n",
        "  print('Specificity:', recall_score(y_test, y_pred_lgbm_clf, average='weighted', pos_label=0))\n",
        "except:\n",
        "  print('Specificity: Undefined')\n",
        "\n",
        "print('G-Mean:', (recall_score(y_test, y_pred_lgbm_clf, average='weighted') * recall_score(y_test, y_pred_lgbm_clf, average='weighted')) ** 0.5)\n",
        "\n",
        "print('Precision:', precision_score(y_test, y_pred_lgbm_clf, average='weighted'))\n",
        "print('Recall:', recall_score(y_test, y_pred_lgbm_clf, average='weighted'))\n",
        "print('F1 Score:', f1_score(y_test, y_pred_lgbm_clf, average='weighted'))\n",
        "print('F0.5 Score:', fbeta_score(y_test, y_pred_lgbm_clf, beta=0.5, average='weighted'))\n",
        "print('F1 Score (weighted):', f1_score(y_test, y_pred_lgbm_clf, average='weighted'))\n",
        "\n",
        "# Compute ROC curve and AUC score\n",
        "# y_prob_lgbm_clf = lgbm_clf.predict_proba(X_test)[:, 1]\n",
        "# fpr, tpr, thresholds = roc_curve(y_test, y_prob_lgbm_clf)\n",
        "# print('ROC Curve:')\n",
        "# print('False Positive Rates:', fpr)\n",
        "# print('True Positive Rates:', tpr)\n",
        "# print('ROC AUC Score:', roc_auc_score(y_test, y_prob_lgbm_clf))\n",
        "\n",
        "# # Compute PR curve and AUC score\n",
        "# precision, recall, thresholds = precision_recall_curve(y_test, y_prob_lgbm_clf)\n",
        "# print('PR Curve:')\n",
        "# print('Precision:', precision)\n",
        "# print('Recall:', recall)\n",
        "# print('PR AUC Score:', average_precision_score(y_test, y_prob_lgbm_clf))\n",
        "\n",
        "# # Compute log loss and Brier score\n",
        "# print('Log Loss:', log_loss(y_test, y_prob_lgbm_clf))\n",
        "# print('Brier Score:', brier_score_loss(y_test, y_prob_lgbm_clf))\n",
        "# print('Brier Skill Score:', brier_score_loss(y_test, y_prob_lgbm_clf) - brier_score_loss(y_test, y_test))"
      ],
      "metadata": {
        "id": "ohDM8Dee7oIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Popular algorithms that can be used for multi-class classification include:\n",
        " - Decision Trees. https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052 https://blog.paperspace.com/decision-trees/ https://www.geeksforgeeks.org/decision-tree-introduction-example/\n",
        " - Naive Bayes.\n",
        " - Random Forest.\n",
        " - Gradient Boosting. https://mlcourse.ai/book/topic10/topic10_intro.html\n",
        "\n",
        "Binary classification algorithms that can use these strategies for multi-class classification include:\n",
        " - Logistic Regression.\n",
        " - Support Vector Machine.\n",
        "\n",
        "Linear discriminant analysis - https://en.wikipedia.org/wiki/Linear_discriminant_analysis https://scikit-learn.org/stable/modules/lda_qda.html\n",
        "\n",
        "labels=[pos_label] - ?\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# create a list of models for voting ensemble\n",
        "ensemble_models = [('rfc', rfc_best), ('knn', knn_best), ('lr', lr_best), ('lgbm', lgbm_best), ('dt', dt_best), ('gb', gb_best)]\n",
        "\n",
        "# create a voting classifier with soft voting\n",
        "voting_clf_soft = VotingClassifier(estimators=ensemble_models, voting='soft')\n",
        "\n",
        "# fit the voting classifier\n",
        "voting_clf_soft.fit(X_train, y_train)\n",
        "\n",
        "# evaluate the voting classifier\n",
        "y_pred_soft = voting_clf_soft.predict(X_test)\n",
        "accuracy_soft = accuracy_score(y_test, y_pred_soft)\n",
        "print(\"Soft voting accuracy:\", accuracy_soft)\n",
        "\n",
        "# voting classifier with hard voting\n",
        "voting_clf_hard = VotingClassifier(estimators=ensemble_models, voting='hard')\n",
        "\n",
        "# fit the voting classifier\n",
        "voting_clf_hard.fit(X_train, y_train)\n",
        "\n",
        "# evaluate the voting classifier\n",
        "y_pred_hard = voting_clf_hard.predict(X_test)\n",
        "accuracy_hard = accuracy_score(y_test, y_pred_hard)\n",
        "print(\"Hard voting accuracy:\", accuracy_hard)\n",
        "\n",
        "<!-- :\n",
        "\n",
        "  a. K-nearest neighbours classifier:\n",
        "    - Confusion Matrix:\n",
        " [ 13  32   6]\n",
        " [ 87 719  28]\n",
        " [  0  25   2]\n",
        "    - Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.13      0.25      0.17        51\n",
        "           1       0.93      0.86      0.89       834\n",
        "           2       0.06      0.07      0.06        27\n",
        "          accuracy                           0.80       912\n",
        "          macro avg       0.37      0.40      0.38       912\n",
        "          weighted avg       0.86      0.80      0.83       912\n",
        "\n",
        "    - Accuracy: 0.8048245614035088\n",
        "    - Sensitivity: 0.8048245614035088\n",
        "    - Specificity: 0.8048245614035088\n",
        "    - G-Mean: 0.8048245614035088\n",
        "    - Precision: 0.8562167661421595\n",
        "    - Recall: 0.8048245614035088\n",
        "    - F1 Score: 0.8282868487082953\n",
        "    - F0.5 Score: 0.8446138570242653\n",
        "    - F1 Score (weighted): 0.8282868487082953\n",
        "\n",
        "\n",
        "  b. Logistic Regression without regularization model\n",
        "  - Confusion Matrix:\n",
        "    [ 29   7  15]\n",
        "    [220 354 260]\n",
        "    [ 10   0  17]\n",
        "  - Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.11      0.57      0.19        51\n",
        "           1       0.98      0.42      0.59       834\n",
        "           2       0.06      0.63      0.11        27\n",
        "           accuracy                           0.44       912\n",
        "           macro avg       0.38      0.54      0.30       91\n",
        "           weighted avg       0.90      0.44      0.56       912\n",
        "\n",
        "  - Accuracy: 0.43859649122807015\n",
        "  - Sensitivity: 0.43859649122807015\n",
        "  - Specificity: 0.43859649122807015\n",
        "  - G-Mean: 0.43859649122807015\n",
        "  - Precision: 0.9047265321998786\n",
        "  - Recall: 0.43859649122807015\n",
        "  - F-Measure: 0.5554150294763841\n",
        "  - F0.5-Measure: 0.7201090277447315\n",
        "  - F1-Measure: 0.5554150294763841\n",
        "\n",
        "\n",
        "\n",
        "  c. Logistic Regression with L2 regularization\n",
        "  - Confusion Matrix:\n",
        "[[ 28   8  15]\n",
        " [221 350 263]\n",
        " [  9   1  17]]\n",
        "  - Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.11      0.55      0.18        51\n",
        "           1       0.97      0.42      0.59       834\n",
        "           2       0.06      0.63      0.11        27\n",
        "           accuracy                           0.43       912\n",
        "           macro avg       0.38      0.53      0.29       912\n",
        "           weighted avg       0.90      0.43      0.55       912\n",
        "\n",
        "  - Accuracy: 0.4331140350877193\n",
        "  - G-Mean: 0.4331140350877193\n",
        "  - Precision: 0.8993231775547051\n",
        "  - Recall: 0.4331140350877193\n",
        "  - F-Measure: 0.5498335728495531\n",
        "  - F0.5-Measure: 0.7143045483386601\n",
        "  - F1-Measure: 0.5498335728495531\n",
        "  - Sensitivity: 0.4331140350877193\n",
        "  - Specificity: 0.4331140350877193\n",
        "\n",
        "d. LGBM classifier\n",
        "  - Confusion Matrix:\n",
        "[[  1  50   0]\n",
        " [  4 829   1]\n",
        " [  0  26   1]]\n",
        "  - Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.20      0.02      0.04        51\n",
        "           1       0.92      0.99      0.95       834\n",
        "           2       0.50      0.04      0.07        27\n",
        "           accuracy                           0.91       912\n",
        "           macro avg       0.54      0.35      0.35       912\n",
        "           weighted avg       0.86      0.91      0.88       912\n",
        "\n",
        "  - Accuracy: 0.9111842105263158\n",
        "  - Sensitivity: 0.9111842105263158\n",
        "  - Specificity: 0.9111842105263158\n",
        "  - G-Mean: 0.9111842105263158\n",
        "  - Precision: 0.8636649462052922\n",
        "  - Recall: 0.9111842105263158\n",
        "  - F1 Score: 0.8759178004958162\n",
        "  - F0.5 Score: 0.8591987280428726\n",
        "  - F1 Score (weighted): 0.8759178004958162 -->"
      ],
      "metadata": {
        "id": "uupmQaux50rr"
      }
    }
  ]
}